{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66603473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Job Title                     Company  \\\n",
      "0              Senior Python Developer    Payne, Roberts and Davis   \n",
      "1                      Energy engineer            Vasquez-Davidson   \n",
      "2                      Legal executive  Jackson, Chambers and Levy   \n",
      "3               Fitness centre manager              Savage-Bradley   \n",
      "4                      Product manager                 Ramirez Inc   \n",
      "..                                 ...                         ...   \n",
      "95  Museum/gallery exhibitions officer     Nguyen, Yoder and Petty   \n",
      "96            Radiographer, diagnostic                  Holder LLC   \n",
      "97              Database administrator              Yates-Ferguson   \n",
      "98                  Furniture designer             Ortega-Lawrence   \n",
      "99                         Ship broker   Fuentes, Walls and Castro   \n",
      "\n",
      "                Location  \n",
      "0        Stewartbury, AA  \n",
      "1   Christopherville, AA  \n",
      "2    Port Ericaburgh, AA  \n",
      "3      East Seanview, AP  \n",
      "4    North Jamieview, AP  \n",
      "..                   ...  \n",
      "95      Lake Abigail, AE  \n",
      "96        Jacobshire, AP  \n",
      "97        Port Susan, AE  \n",
      "98     North Tiffany, AA  \n",
      "99     Michelleville, AP  \n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Webscraping to build my own dataset\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import csv \n",
    "import pandas as pd\n",
    "\n",
    "# The website I'm scraping\n",
    "URL = \"https://realpython.github.io/fake-jobs/\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "# Collecting the relevant data\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "results = soup.find(id=\"ResultsContainer\")\n",
    "job_elements = results.find_all(\"div\", class_=\"card-content\")\n",
    "\n",
    "# Creating the header for the .csv file\n",
    "header = ['Job Title','Company','Location']\n",
    "\n",
    "# wrting data to my newly created .csv file\n",
    "with open('PythonJobListingsDataSet.csv','w', newline='', encoding='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for job_element in job_elements:\n",
    "        title_element = job_element.find(\"h2\", class_=\"title\")\n",
    "        company_element = job_element.find(\"h3\", class_=\"company\")\n",
    "        location_element = job_element.find(\"p\", class_=\"location\")\n",
    "        data = [title_element.text.strip(),company_element.text.strip(),location_element.text.strip()]\n",
    "        writer.writerow(data)\n",
    "\n",
    "# Reading the file that was created\n",
    "df = pd.read_csv(r'C:\\Users\\Brady\\PythonJobListingsDataSet.csv')\n",
    "\n",
    "print(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5602fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31ddcde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
